"""Pydantic models for the API."""

from typing import Any, Optional
from pydantic import BaseModel, Field


class FragmentSchema(BaseModel):
    """Schema for a generated code fragment."""
    commentary: str = Field(
        description="Describe what you're about to do and the steps you want to take for generating the fragment in great detail."
    )
    template: str = Field(
        description="Name of the template used to generate the fragment."
    )
    title: str = Field(
        description="Short title of the fragment. Max 3 words."
    )
    description: str = Field(
        description="Short description of the fragment. Max 1 sentence."
    )
    additional_dependencies: list[str] = Field(
        default_factory=list,
        description="Additional dependencies required by the fragment."
    )
    has_additional_dependencies: bool = Field(
        default=False,
        description="Detect if additional dependencies are required."
    )
    install_dependencies_command: str = Field(
        default="",
        description="Command to install additional dependencies."
    )
    port: Optional[int] = Field(
        default=None,
        description="Port number used by the resulted fragment."
    )
    file_path: str = Field(
        description="Relative path to the file, including the file name."
    )
    code: str = Field(
        description="Code generated by the fragment. Only runnable code is allowed."
    )


class MorphEditSchema(BaseModel):
    """Schema for morph edit instructions."""
    commentary: str = Field(description="Explain what changes you are making and why")
    instruction: str = Field(description="One line instruction on what the change is")
    edit: str = Field(description="The code changes with // ... existing code ... for unchanged parts")
    file_path: str = Field(description="Path to the file being edited")


class LLMModel(BaseModel):
    """LLM model information."""
    id: str
    name: str
    provider: str
    providerId: str
    multiModal: Optional[bool] = False


class LLMModelConfig(BaseModel):
    """LLM configuration."""
    model: Optional[str] = None
    apiKey: Optional[str] = None
    baseURL: Optional[str] = None
    temperature: Optional[float] = None
    topP: Optional[float] = None
    topK: Optional[int] = None
    frequencyPenalty: Optional[float] = None
    presencePenalty: Optional[float] = None
    maxTokens: Optional[int] = None


class MessageContent(BaseModel):
    """Content of a message."""
    type: str  # 'text', 'image', 'code'
    text: Optional[str] = None
    image: Optional[str] = None


class Message(BaseModel):
    """A chat message."""
    role: str  # 'user', 'assistant', 'system'
    content: list[MessageContent] | str


class ChatRequest(BaseModel):
    """Request body for the chat endpoint."""
    messages: list[dict[str, Any]]
    userID: Optional[str] = None
    teamID: Optional[str] = None
    template: dict[str, Any]
    model: LLMModel
    config: LLMModelConfig
    currentFragment: Optional[FragmentSchema] = None


class SandboxRequest(BaseModel):
    """Request body for the sandbox endpoint."""
    fragment: FragmentSchema
    userID: Optional[str] = None
    teamID: Optional[str] = None
    accessToken: Optional[str] = None


class ExecutionResultWeb(BaseModel):
    """Execution result for web apps."""
    sbxId: str
    template: str
    url: str


class ExecutionResultInterpreter(BaseModel):
    """Execution result for code interpreter."""
    sbxId: str
    template: str
    stdout: list[str]
    stderr: list[str]
    runtimeError: Optional[dict] = None
    cellResults: list[Any]

